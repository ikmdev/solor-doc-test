<?xml version="1.0" encoding="UTF-8"?>
<?xml-model href="http://docbook.org/xml/5.1/rng/docbook.rng" schematypens="http://relaxng.org/ns/structure/1.0"?>
<?xml-model href="http://docbook.org/xml/5.1/sch/docbook.sch" type="application/xml" schematypens="http://purl.oclc.org/dsdl/schematron"?>
<chapter xmlns="http://docbook.org/ns/docbook"
    xmlns:xlink="http://www.w3.org/1999/xlink" version="5.1">
    <title>Summary of Findings: Technologies that Support Harmonization of Terminology Standards</title>
    <section>
        <title>Introduction</title>
        <para>Health IT standards are critical for representing and sharing health data in a large
            health ecosystem. Multiple users with roles in various fields can produce and access
            health data, compelling the need for a common way to format the data standards. This is
            particularly important for data encoded in EHRs and LISs. Standards, such as SNOMED CT®,
            LOINC®, and RxNorm , provide a common language for certain types of health information
            to be represented and understood. However, multiple industry knowledge standards exist
            in a variety of environments and need to be harmonized to ensure data interoperability.
            An IKM platform is needed to harmonize these standards, ultimately generating high
            quality data for downstream use. </para>
        <para>Knowledge standards are currently managed by different organization and stakeholder
            groups. These standards are often promulgated by the organizations to advance their use;
            however, the evolution of these standards occur in silos, compounding the complexity of
            standard harmonization. Clinical data and concepts can be represented by multiple
            standards, leading to overlap, and impeding the ability to recognize semantic
            equivalence between the standards. A core component of standard harmonization is the
            ability to maintain both structure and meaning to ensure data integrity.
            Interoperability challenges arise when only one of these tenants is observed. These
            challenges lead to misinterpretations, inefficiencies, and declines in patient safety. </para>
        <para>An IKM Platform is needed to harmonize standards and promote data interoperability
            across the ecosystem. In an integrated laboratory data ecosystem, knowledge can freely
            flow between systems in a smooth exchange. Benefits of this exchange include improved
            collaboration, incorporation of advanced analytical tools, and true data
            interoperability. The need for a knowledge management platform and integrated laboratory
            data system is the same; coordinating knowledge management practices across
            organizations and systems to achieve a safe and effective healthcare system. </para>
        <section>
            <title>Findings</title>
            <para>While HRO principles and IKM serve as a well-structured architecture to support
                the harmonization and standardization of disparate clinical terminology standards,
                there are key advancements that must be made and technologies that must be utilized
                to optimize this work. </para>
            <section>
                <title>Data Management</title>
                <para>Data management is the safe and efficient storage, management, and use of
                    collected data to support informed decision making and improve outcomes for
                    individuals and organizations. This is a critical area of the healthcare
                    enterprise that must undergo advancements to support optimized knowledge
                    standard harmonization, improved patient safety and outcomes, and enhanced data
                    quality. [1] While data management covers a wide range of processes and
                    functions, this work focuses on three key areas: </para>
                <orderedlist>
                    <listitem>
                        <para><emphasis role="bold">Ease of Access</emphasis> – While an increasing
                            number of healthcare organizations rely on IT systems to store, manage,
                            and access data collected from a variety of sources, the ability to
                            identify, access, and then utilize that data in an impactful and
                            meaningful way is an ongoing challenge. This work aims to improve both
                            the author’s and user’s ability to efficiently capture data from across
                            the healthcare ecosystem and to effectively analyze that data for
                            actionable decision making. </para>
                    </listitem>
                    <listitem>
                        <para><emphasis role="bold">Integrating Disparate Data Sources</emphasis> –
                            As healthcare organizations capture data from different sources, it is
                            critical that disparate terminology standards and data representation
                            can be integrated into a common model. While various terminology
                            standards exist, the formatting and representation of clinical data
                            across standards can vary significantly, leading to issues with data
                            interoperability and suboptimal concept representation between standards
                            and systems. Using a standardized and repeatable process, our team will
                            work to ensure the common model can integrate and represent data from a
                            variety of sources, including well established standards and newly
                            emerging systems. </para>
                    </listitem>
                    <listitem>
                        <para><emphasis role="bold">Data Integrity</emphasis> – Patient care and
                            patient safety are innately tied to the quality and integrity of their
                            healthcare data. Currently, as data is transferred within and between
                            healthcare systems, including EHRs, LISs, and pharmaceutical systems, it
                            can often lose meaning and pertinent information regarding relationships
                            and associated concepts. This work will develop a common model that will
                            use a standardized process to ensure data integrated from disparate data
                            sources maintains meaning and all pertinent information throughout data
                            transmission, storage, and use. Tools such as universally unique
                            identifiers (UUID) will support Tinkar with the identification of
                            semantically equivalent concepts and support optimal data representation
                            across terminology standards. </para>
                    </listitem>
                </orderedlist>
                <para><emphasis>Tinkar</emphasis>
                </para>
                <para>Tinkar is a self-describing knowledge architecture intended to represent other
                    terminology standards in a human readable and machine processable format. Tinkar
                    supports improvements to data management by integrating terminology standards
                    into a common model that efficiently captures granular details and data sources
                    of each standard for rapid and scalable data querying and analysis while
                    maintaining meaning. Versioning is another important component of maintaining
                    data integrity. Tinkar will maintain a detailed version history to clearly
                    convey how concepts have changed over time and will allow authors to preview or
                    test edits to concepts before pushing to a live environment to maintain
                    appropriate concept representations and relationships. [2] As new healthcare
                    systems or terminology standards emerge, the data they represent will be
                    “Tinkarized” and integrated into Tinkar and the IKM architecture. </para>
                <para><emphasis>Protocol Buffers</emphasis>
                </para>
                <para>Protocol buffers are an agnostic and unopinionated way to represent structured
                    and packeted data that can easily be pushed or pulled to different IT systems.
                    This system and standard-neutral representation of data allows a wider range of
                    systems and coding languages to read the same data than traditional methods and
                    supports rapid data transmission, long-term storage, forward and backward
                    compatibility, and improved data querying. Protocol buffers will allow Tinkar to
                    import an encoded concept from one system’s terminology standard, store and
                    manage that data, and then transmit that data with maintained data integrity to
                    another system to display the concept in the disparate, local terminology
                    standard. [3] </para>
                <para><emphasis>UUID version 5</emphasis>
                </para>
                <para>UUID version 5 uses a 128-bit label to idempotently represent data in a
                    completely unique and unambiguous way. Idempotent data representation means that
                    identical seed values or concepts will be labeled with the same UUID, supporting
                    identification of semantically equivalent concepts within and between
                    terminology standards and optimized access to data. Additionally, by labeling
                    each concept, semantic, and pattern within Tinkar with a UUID, our team is able
                    to integrate a variety of terminology standards while avoiding duplicative or
                    redundant concepts, preventing accidental and inappropriate labeling of a
                    concept or component, and harmonizing internal representation of knowledge
                    standards. [4] </para>
            </section>
        </section>
        <section>
            <title>Change Management</title>
            <para>Change management is simply an approach to identify, implement, and support
                necessary organizational changes. Despite each terminology standard and healthcare
                system employing some form of change management, they are implemented asynchronously
                and lack detailed tracking and communication of changes. Even within a terminology
                standard the change management for models, definitions, and structure can vary in
                time and frequency. Supporting harmonization of knowledge standards through IKM
                requires a comprehensive change management strategy to track, identify, and reflect
                independent changes across systems to appropriately represent updated concepts in
                Tinkar based on source code changes. </para>
            <para><emphasis>Change Sets</emphasis>
            </para>
            <para>Change sets are a group of changes that are accompanied by meta-information that
                clearly and concisely describe the packaged changes as they are committed to a live
                environment. Change sets support optimized change management by providing granular
                details of each change and enables revisions to be made if concept changes need
                corrections. [5] </para>
            <para><emphasis>STAMP</emphasis>
            </para>
            <para>STAMP is a syntax used to represent current and previous terminology assets
                (Concepts, patterns, and semantics) in Tinkar using the following five requirements: </para>
            <para>
                <orderedlist>
                    <listitem>
                        <para><emphasis role="bold">Status</emphasis> – The status is an indication
                            of whether an asset is active or inactive.</para>
                    </listitem>
                    <listitem>
                        <para><emphasis role="bold">Time</emphasis> – The time and time zone at
                            which a change was recorded.</para>
                    </listitem>
                    <listitem>
                        <para><emphasis role="bold">Author</emphasis> – The author of a change,
                            identified using the appropriate granularity.</para>
                    </listitem>
                    <listitem>
                        <para><emphasis role="bold">Module</emphasis> – The module is an
                            organizational label for the larger asset to which a component belongs,
                            such as code, system, or edition.</para>
                    </listitem>
                    <listitem>
                        <para><emphasis role="bold">Path</emphasis> – The path is a production
                            component of the previously defined organization, such as development,
                            testing, staging, or deployment. [2] </para>
                    </listitem>
                </orderedlist>
            </para>
            <para>STAMP is not only used to version Tinkar data, but it is also a requirement for
                all Tinkar assets, existing and new. Ensuring all data follows this syntax supports
                optimal change management and versioning practices, like maintaining detailed
                versioning history by marking concepts as active or inactive rather than deleting
                prior versions, identifying authors of each version to know who and when concepts
                were changed, and testing and previewing changes before they are pushed to a live
                environment. [2] </para>
            <para><emphasis>Key Value Store </emphasis></para>
            <para>A key value store, or key value database, stores data as a value and assigns a key
                to that data, which is then used to track, retrieve, and update or change the data
                associated with a given key. When used in parallel with STAMP, a key value store
                would maintain the key for a certain value/data whose status changed from active to
                inactive or underwent other changes to update author and time, further supporting
                Tinkar's detailed versioning and change management best practices. This type of
                database would also support rapid and efficient querying of healthcare data to
                support improved patient outcomes, public health trends, and policy making. [6] </para>
        </section>
        <section>
            <title>Dependency Management</title>
            <para>Harmonization of multiple terminology standards and healthcare systems using IKM
                will require an extensive approach to dependency management, the process and
                approach to managing dependencies between people, process, and systems. With Tinkar,
                outputs to one system can often originate from a wide range of terminology standards
                or systems, which leads to multiple dependencies. It is not only important for our
                team to identify dependencies, but we must also categorize them to understand the
                direction, frequency, and type of dependency and to optimally prioritize and
                mitigate potential issues caused by these relationships. For example, Laboratory
                Interoperability Data Repository (LIDR) has a dependency on both SNOMED CT® and
                LOINC® and when SNOMED CT® or LOINC® are updated, validation must be performed in a
                comprehensive manner to determine if LIDR is correctly using the current
                interpretation of said dependent standards (SNOMED CT® and LOINC®). As works
                continues towards IKM, it is critical that technologies are selected and implemented
                that will support the management of these dependencies to reduce patient safety
                issues and unnecessary complications. [7] </para>
            <para><emphasis>Maven</emphasis>
            </para>
            <para>Maven is a project management tool with dependency management features for
                complex, multi-module projects. Maven compliments STAMP and key value stores because
                it allows project owners to name artifacts and specify the version and build stage
                (development, testing, deployment, etc.) involved in a dependency. Maven can also
                import dependencies from other projects, supporting continual process improvement
                and integration of new systems and terminology standards. [8] </para>
            <para><emphasis>Nexus</emphasis>
            </para>
            <para>Nexus is a repository used to manage components, binaries, and build artifacts
                across software. In Komet, which is described below, this allows the developer to
                organize and control the versions of data that are released, stored, and made
                available to users. Nexus provides enterprise control through centralization,
                storage, development support, and scale. [9] </para>
            <para><emphasis>Origin data</emphasis>
            </para>
            <para>An optimized representation of a source knowledge standard is generated to
                simplify the process of putting the standard’s data into a common model. This data
                will leverage Maven and Nexus to manage dependency complexity of systems using
                Tinkar data, since individual knowledge standards have both physical and logical
                models for how they are constructed, packaged, and distributed. An important aspect
                in managing the dependency of harmonized standards is organizing the source data
                (raw) into structures. Origin data will repackage the source terminology data into a
                consistent and readable format, which alleviates the need to write individual ways
                to parse and read through the different variations of file structures. Origin data
                also allows the addition of data that is not found in the source terminology data
                (e.g., provenance, dependencies [LIDR depends on LOINC® and SNOMED®]). </para>
            <para><emphasis>Starter data</emphasis>
            </para>
            <para>Tinkar starter data acts as the foundational dataset. It conforms to the Tinkar
                data model and is the minimum viable dataset required for Komet usability. The
                Tinkar starter data consists of a Tinkar concept model hierarchy which defines
                origin and destination (a.k.a. parent/child) concept relationships, as well as
                Tinkar patterns which define the structure and usage for how Tinkar concepts may be
                represented. The Tinkar data model is extendable and allows for the importation and
                harmonization of other terminology standards such as SNOMED CT® and LOINC® and
                enables a lossless transformation of knowledge standards to the Tinkar format.
                Starter data will leverage Maven and Nexus to manage dependency complexity of
                systems using Tinkar data. </para>
        </section>
        <section><title>User Interface (UI) and Experience (UX)</title>
                        <para>Harmonizing self-sustaining and contained knowledge standards requires
                a robust and tailored UI/UX design. A strong UI/UX interface meets the needs of the
                user, is intuitive to use, and provides an environment for tackling complex
                terminological overlaps between various standards which is needed for properly
                harmonized knowledge. Without a good user interface, work to harmonize standards
                cannot be done. Good UI/UX design provides users a visible interface to work with
                different coding standards. Users come from a variety of backgrounds including
                laboratory technicians, clinicians, researchers, regulatory personnels, and others
                and cannot all be expected to be proficient coders who can readily access and use
                the backend software/coding language. Good UI/UX is built off human centric design
                principles, is tailored to different roles and needs, and provides components that
                give the user the ability to create, edit, and retire knowledge. Tinkar core is the
                harmonization which lives in the backend, but UI/UX provides an interface that
                allows users to interact with the logic and harmonize between different coding
                standards. UI/UX can also incorporate features such as multiple languages and
                dialects, which allow for a user to have a tailored experience and can be focused on
                a particular regional preference for descriptions and other text information to
                emphasize different features which may prompt the desired response or use from the
                specific user. </para>
            <para><emphasis>Komet</emphasis>
            </para>
            <para>Komet serves as the reference implementation for IKM capabilities. Komet will
                combine developer tools into one graphical UI that will allow developers to write,
                edit, debug, compile code, and automate tasks for software development. [10] Komet
                will be open-source, meaning the code being developed is open to the public and
                available for all to edit and distribut. This decentralized production model is a
                movement in the software community and has led to major advancements in code and is
                often cheaper, flexible, and has more permanency that private or proprietary
                software. [11] Komet has automated features such as a text editor, build automation,
                and debugger, and can support additional features like refactoring, code search, and
                continuous integration and continuous deployment (CI/CD) tools. Komet supports plug
                ins and extensions for developers to customize workflows and needs. [12] All
                standard harmonization will be facilitated within Komet. </para>
            <para><emphasis>Coordinates</emphasis>
            </para>
            <para>Tinkar is the data model for knowledge harmonization and IKM. The ability to query
                these Tinkar representations, such as comparing active and inactive components
                (representations) across time, is achieved through coordinates. [2] Coordinates
                include concepts such as STAMP, language, dialect, clinical domains, and more. STAMP
                is the most basic of the coordinates, and through which all content is filtered.
                Examples of STAMP coordinates include the most recent version, a set of data from
                several versions, and all active components only. </para>
            <para>• <emphasis role="bold">Language Coordinates</emphasis> control the terms to be
                displayed based on a language/dialect and list of synonyms. </para>
            <para>• <emphasis role="bold">Logic Coordinates</emphasis> identify results from
                Description Logic Classifiers and different output versions over time. </para>
            <para>• <emphasis role="bold">Navigation Coordinates</emphasis> allow users to view and
                search certain concepts, with examples including stated versus inferred
                relationships for SNOMED CT®, and concepts included/excluded for certain domains. </para>
            <para>The ability to search, display, and navigate concepts and semantics requires the
                ability to calculate combinations of content based on different coordinates. The
                current Tinkar reference model is expressive enough to represent any terminology and
                future iterations will require harmonized implementation guides for each
                terminology. [2] </para>
        </section>
        <section>
            <title>Quality Assurance (QA)</title>
            <para>Quality assurance (QA) is important when harmonizing knowledge standards and is
                critical when assessing if a software meets the users’ requirements. Constraints can
                be used to perform general QA on content that is represented in a Tinkar
                implementation and is part of business requirements. Constraints in Tinkar are used
                to represent standard terminology artifacts and are used to ensure terminologies
                represented in an implementation are consistent when queried and displayed, and
                ultimately ensure the integration is high quality and reliable for patient care.
                Furthermore, to ensure the quality of items that are transformed and integrated
                together a type of classifier can be created to check for issues or errors in Tinkar
                data. </para>
            <para><emphasis>ELK Classifier </emphasis></para>
            <para>Komet’s ability to use a description logic classifier to detect equivalences and
                errors between concepts is important when harmonizing knowledge standards. In
                particular, the ELK Classifier, a description-logic classifier, is an ontology
                reasoner that supports Web Ontology Language (OWL) 2 Existential Logic (EL) profile
                and provides a quick reasoning engine for OWL EL because current features and
                reasoning tasks are limited (although this is fine for SNOMED CT®). This classifier
                reasons over Tinkar data and distinguishes if the asserted facts on concepts (via
                semantics) are true. [13] </para>
        </section>
    </section>
    <section>
        <title>Conclusion</title>
        <para>Disparate terminology standards and healthcare systems continue to plague today’s
            healthcare ecosystem with patient safety challenges associated with data quality and
            interoperability. To improve patient outcomes and support informed policy and public
            health decision making, comprehensive and holistic IKM is needed. Harmonizing
            terminology standards will ensure data can be transmitted within and between healthcare
            systems while maintaining meaning, associated concepts, and other pertinent information.
            This paper outlines various technologies and tools that are needed to support critical
            aspects of IKM. </para>
        <para>As our team continues to work towards the harmonization of terminology standards
            through Tinkar and IKM, it is critical that we continue to refine and incorporate the
            various components of data, change, and dependency management and quality assurance
            mentioned above. The components outlined in this paper are not exhaustive and will
            evolve as our team continues with our work and as new information emerges. </para>
    </section>
    <section>
        <title>References</title>
        <para>1. What is Data Management? [Internet]. [cited 2023 Jun 1]. Available from:
            https://www.oracle.com/database/what-is-data-management/ </para>
        <para>2. HL7 Logical Model: Standardized Terminology Knowledgebase, Release 1. Terminology
            Knowledge Architecture Informative Ballot. HL7 Vocabulary Work Group. August 2021.
            https://www.hl7.org/documentcenter/private/standards/HL7_LM_TERM_KB_R1_INFORM_2021AUG_FINAL.pdf </para>
        <para>3. Protocol Buffers - Overview [Internet]. [cited 2023 Jun 1]. Available from:
            https://protobuf.dev/overview/ </para>
        <para>4. Universally Unique Identifier [Internet]. Wikimedia Foundation; 2023 [cited 2023
            Jun 1]. Available from:
            https://en.wikipedia.org/wiki/Universally_unique_identifier#Versions_3_and_5_(namespace_name-based) </para>
        <para>5. Changeset [Internet]. Wikimedia Foundation; 2022 [cited 2023 Jun 1]. Available
            from: https://en.wikipedia.org/wiki/Changeset </para>
        <para>6. What is a Key-Value Database? [Internet]. [cited 2023 Jun 1]. Available from:
            https://www.mongodb.com/databases/key-value-database </para>
        <para>7. Rogers P. Dependency Management Techniques [Internet]. A Path Less Taken; 2022
            [cited 2023 Jun 1]. Available from:
            https://medium.com/agile-outside-the-box/dependency-management-techniques-187f888a6aad </para>
        <para>8. Porter B, Laugstol T, Marbaise KH. Apache Maven Project - Introduction to the
            Dependency Mechanism [Internet]. [cited 2023 Jun 1]. Available from:
            https://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html </para>
        <para>9. Sonatype Nexus Repository - Binary and Artifact Management | Sonatype [Internet].
            www.sonatype.com. Available from:
            https://www.sonatype.com/products/sonatype-nexus-repository </para>
        <para>10. Okeke F. The 12 best IDEs for programming [Internet]. TechRepublic. 2022.
            Available from: https://www.techrepublic.com/article/best-ide-software/ </para>
        <para>11. Redhat. What is open source? [Internet]. Redhat.com. 2019. Available from:
            https://www.redhat.com/en/topics/open-source/what-is-open-source </para>
        <para>12. RedHat. What is an IDE? [Internet]. Redhat.com. 2019. Available from:
            https://www.redhat.com/en/topics/middleware/what-is-ide </para>
        <para>13. OwlFeatures [Internet]. GitHub. [cited 2023 Jun 2]. Available from:
            https://github.com/liveontologies/elk-reasoner/wiki/OwlFeatures </para>
    </section>
</chapter>
